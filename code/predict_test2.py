# predict_test.py

import json
import torch
from transformers import BertTokenizerFast, BertForTokenClassification
from labels import id2label
import os

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ==== é…ç½®ä¿®æ”¹åŒº ====
MODEL_PATH = "D:\enæ¨¡å‹\model_checkpoints\checkpoints\checkpoint-2000"
TEST_PATH = "test1.json"
OUTPUT_PATH = "demomin.txt"

# ==== æ‰©å±•çš„ä»‡æ¨è§¦å‘è¯è¡¨ ====
RACISM_TRIGGERS = ["é»‘äºº", "é»‘é¬¼", "é»‘çš®", "åŠ£ç§", "ä½äººç§", "é»„çš®çŒ´", "é»„ç§äºº", "ç™½å·¦", "æ´‹å¥´", "éæ´²","éé»˜", "é»‘","çŠ¹å¤ª","çŒ©çŒ©","å˜¿äºº"]
REGION_TRIGGERS = ["æ²³å—", "å¹¿å·", "ä¸Šæµ·", "ä¸œåŒ—", "ç¦å»º", "æ¹–åŒ—", "æ²³åŒ—", "æ–°ç–†", "åŒ—æ–¹", "å®‰å¾½","å¹¿è¥¿", "å—æ–¹", "é’æµ·", "æ±Ÿå—", "å±±è¥¿", "é™•", "ç”˜è‚ƒ", "é»‘é¾™æ±Ÿ", "è¾½å®", "å‰æ—"]
GENDER_TRIGGERS = ["å¥³æ‹³", "å¥³æƒç™Œ", "æ¯çŒª", "å¹•åˆƒ", "ç”·äºº", "å›½å¥³", "å›½é“", "ä¸é…ç»“å©š", "ç»¿èŒ¶", "ä¸é…ç”Ÿè‚²","å°ä»™å¥³", "å¥³äºº", "æ™®ä¿¡ç”·", "å¥³", "ç”·", "å¦¹", "é¾Ÿç”·", "èˆ”ç‹—", "å¥³çŠ¬", "æ‹³"]
LGBTQ_TRIGGERS = ["åŸºä½¬", "åŒ",  "gay"]
OTHERS_TRIGGERS = ["æ—¶ä»£"]

HATE_TRIGGER_WORDS = (
    RACISM_TRIGGERS + REGION_TRIGGERS + GENDER_TRIGGERS + LGBTQ_TRIGGERS + OTHERS_TRIGGERS
)

GROUP_HINTS = {
    "Racism": RACISM_TRIGGERS,
    "Region": REGION_TRIGGERS,
    "Sexism": GENDER_TRIGGERS,
    "LGBTQ": LGBTQ_TRIGGERS,
    "others": OTHERS_TRIGGERS
}

# ==== åŠ è½½æ¨¡å‹ ====
tokenizer = BertTokenizerFast.from_pretrained(MODEL_PATH)
model = BertForTokenClassification.from_pretrained(MODEL_PATH).to(device)
model.eval()


# ==== å·¥å…·å‡½æ•° ====
def load_data(path):
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)  # JSON array æ ¼å¼


def extract_spans(tokens, labels):
    spans = {"Target": [], "Argument": [], "Group": [], "Hate": []}
    current_type = None
    current_tokens = []

    for tok, lab in zip(tokens, labels):
        label = id2label.get(lab, "O")
        if label == "O":
            if current_type:
                spans[current_type].append("".join(current_tokens))
                current_type = None
                current_tokens = []
        elif label.startswith("B-"):
            if current_type:
                spans[current_type].append("".join(current_tokens))
            current_type = label[2:]
            current_tokens = [tok]
        elif label.startswith("I-") and current_type == label[2:]:
            current_tokens.append(tok)
        else:
            current_type = None
            current_tokens = []

    if current_type and current_tokens:
        spans[current_type].append("".join(current_tokens))
    return spans


def postprocess(spans, text):
    # é»˜è®¤å€¼
    hate = "hate" if spans["Hate"] else "non-hate"
    group = spans["Group"] or []

    # === ğŸ†• è¯„è®ºå¯¹è±¡ï¼ˆTargetï¼‰ + è®ºç‚¹ï¼ˆArgumentï¼‰åˆ†æ ===
    targets = spans.get("Target", [])
    arguments = spans.get("Argument", [])

    # æ‹¼æ¥ååˆ¤å®šæ˜¯å¦åŒ¹é…è§¦å‘è¯
    combined_texts = []
    for t in targets:
        for a in arguments:
            combined_texts.append(t + a)
            combined_texts.append(a + t)  # é¿å…é”™ä½é¡ºåº

    # === ğŸ” Hate åˆ¤æ–­å¼ºåŒ– ===
    if hate == "non-hate":  # æ¨¡å‹æœªåˆ¤æ–­ä¸º hate
        strings_to_check = [text] + combined_texts
        for s in strings_to_check:
            if any(word in s for word in HATE_TRIGGER_WORDS):
                hate = "hate"
                break

    # === ğŸ” Group åˆ†æå¼ºåŒ– ===
    if not group:
        strings_to_check = [text] + combined_texts
        for s in strings_to_check:
            for cat, keywords in GROUP_HINTS.items():
                if any(word in s for word in keywords):
                    group = [cat]
                    break
            if group:
                break
        if not group:
            group = ["non-hate"]

    return hate, group


def combine_to_quadruples(spans, hate, group):
    targets = spans["Target"] or ["NULL"]
    arguments = spans["Argument"] or ["NULL"]
    results = []

    for t in targets:
        for a in arguments:
            for g in group:
                results.append(f"{t} | {a} | {g} | {hate}")
    return results


def predict(text):
    inputs = tokenizer(text, return_tensors='pt', truncation=True).to(device)
    with torch.no_grad():
        outputs = model(**inputs)
    preds = torch.argmax(outputs.logits, dim=-1).squeeze().tolist()
    tokens = tokenizer.tokenize(text)
    pred_labels = preds[1:len(tokens)+1]
    spans = extract_spans(tokens, pred_labels)
    hate_flag, group_list = postprocess(spans, text)
    quads = combine_to_quadruples(spans, hate_flag, group_list)
    return quads


# ==== ä¸»ç¨‹åº ====
if __name__ == "__main__":

    test_data = load_data(TEST_PATH)

    with open(OUTPUT_PATH, "w", encoding="utf-8") as fout:
        for sample in test_data:
            text = sample["content"]
            quads = predict(text)
            output_line = " [SEP] ".join(quads) + " [END]"
            fout.write(output_line + "\n")
            print(f"[è¾“å…¥] {text}")
            print(f"[è¾“å‡º] {output_line}\n")

    print(f"âœ… å·²å®Œæˆé¢„æµ‹ï¼Œè¾“å‡ºæ–‡ä»¶ï¼š{OUTPUT_PATH}")